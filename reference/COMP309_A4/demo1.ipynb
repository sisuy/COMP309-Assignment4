{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'missingno'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_11396/2457238538.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m# Visualisation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mmissingno\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mmsno\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;31m# Modelling Algorithms -Regression:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'missingno'"
     ]
    }
   ],
   "source": [
    "# Handle table-like data and matrices :\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "# Modelling Algorithms -Regression:\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# Modelling Helpers :\n",
    "from sklearn.model_selection import train_test_split\n",
    "#preprocessing :\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "# Regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error \n",
    "# Ignore warnings :\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scipy.stats as sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diamonds.csv\")# load dataset\n",
    "print(df.head(10))#visualise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'] , axis=1 , inplace=True)# remove the first column\n",
    "print(df.head(5))# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum()) # Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df,labels=True)#visualizig that there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can see the summry of the x, y and z min values are 0 which is impossible \n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking to see how many unreasonable values in dataset\n",
    "print(df.loc[(df['x']==0) | (df['y']==0) | (df['z']==0)])\n",
    "print(df.loc[(df['x']>20) | (df['y']>20) | (df['z']>20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.loc[(df['x']==0) | (df['y']==0) | (df['z']==0)]))\n",
    "print(len(df.loc[(df['x'] >20) | (df['y'] >20) | (df['z']>20)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I dropped them as they don't make sense------Outliers && Zero\n",
    "df = df[(df[['x', 'y', 'z']] != 0).all(axis=1)]\n",
    "df = df[(df[['x', 'y', 'z']] < 20).all(axis=1)]\n",
    "#Check wether they has been removed\n",
    "print(len(df.loc[(df['x']==0) | (df['y']==0) | (df['z']==0)]))\n",
    "print(len(df.loc[(df['x'] >20) | (df['y'] >20) | (df['z']>20)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping the categorical variables\n",
    "mappingCut = {'Fair': 60,'Ideal': 100, 'Good': 70,'Very Good': 80, 'Premium': 90}\n",
    "mappingCla = {'I1': 30, 'SI1': 40, 'SI2': 50, 'VS1': 60, 'VS2': 70, 'VVS1': 80, 'VVS2': 90, 'IF': 100}\n",
    "mappingCol = {'J': 40, 'I': 50 , 'H': 60, 'G': 70,'F': 80 ,'E': 90, 'D': 100}\n",
    "df = df.replace({'cut': mappingCut, 'clarity': mappingCla, 'color':mappingCol})\n",
    "\n",
    "corr = df.corr()# looking at the correlation of the variables to price\n",
    "sns.heatmap(data = corr, square = True, annot = True, cbar = True, linewidths = 0.5,cmap='ocean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.set(color_codes=True)\n",
    "# sns.distplot(df['price'])# looking for skew "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # log transform as there is a skew and not linear and need it for the algorithms: \n",
    "# #The log transformation can be used to make highly skewed distributions less skewed. \n",
    "# #This can be valuable both for making patterns in the data more interpretable and for helping to meet the assumptions of inferential statistics.\n",
    "# X = df.drop(['price'], axis = 1)\n",
    "# y = np.log(df['price'])\n",
    "# sns.set(color_codes=True)\n",
    "# sns.distplot(y)# check if it is repaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #sns.distplot(df['price'])\n",
    "# sns.factorplot(data = X, kind = 'box', size = 4, aspect = 2.5)# looking at the range of all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = X.columns\n",
    "# # feature scaling - standardising\n",
    "# scaler = StandardScaler().fit(X)\n",
    "# X = scaler.transform(X)\n",
    "# # changing back to a dataframe from an array\n",
    "# X = pd.DataFrame(X, columns = names)\n",
    "# # looking at the range after scaling\n",
    "# sns.factorplot(data = X, kind = 'box', size = 4, aspect = 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 309)\n",
    "Trainset,Testset = train_test_split(df, test_size = 0.3, random_state = 309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_11396/2762528479.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrain_data_copy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTrainset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mX_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_data_copy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"price\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0my_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTrainset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"price\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mtest_data_copy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mTestset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m;\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Trainset' is not defined"
     ]
    }
   ],
   "source": [
    "train_data_copy = Trainset.copy()\n",
    "X_train = train_data_copy.drop([\"price\"],axis=1)\n",
    "y_train = Trainset[\"price\"]\n",
    "   \n",
    "test_data_copy=Testset.copy();\n",
    "X_test = test_data_copy.drop([\"price\"],axis=1)\n",
    "y_test = test_data_copy[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(18, 10))\n",
    "    axs = axs.ravel()\n",
    "    axs[0].scatter(Trainset.carat,   Trainset.price, alpha = 0.2, s = 1)\n",
    "    axs[0].set_xlabel('Carat')\n",
    "    axs[1].scatter(Trainset.cut,     Trainset.price, alpha = 0.2, s = 1)\n",
    "    axs[1].set_xlabel('Cut')\n",
    "    axs[2].scatter(Trainset.color,   Trainset.price, alpha = 0.2, s = 1)\n",
    "    axs[2].set_xlabel('Color')\n",
    "    axs[3].scatter(Trainset.clarity, Trainset.price, alpha = 0.2, s = 1)\n",
    "    axs[3].set_xlabel('Clarity')\n",
    "    axs[4].scatter(Trainset.depth,   Trainset.price, alpha = 0.2, s = 1)\n",
    "    axs[4].set_xlabel('Depth')\n",
    "    axs[5].scatter(Trainset.table,   Trainset.price, alpha = 0.2, s = 1)\n",
    "    axs[5].set_xlabel('Table')\n",
    "    axs[6].scatter(Trainset.x,       Trainset.price, alpha = 0.2, s = 1)\n",
    "    axs[6].set_xlabel('x')\n",
    "    axs[7].scatter(Trainset.y,       Trainset.price, alpha = 0.2, s = 1)\n",
    "    axs[7].set_xlabel('y')\n",
    "    axs[8].scatter(Trainset.z,       Trainset.price, alpha = 0.2, s = 1)\n",
    "    axs[8].set_xlabel('z')\n",
    "    for i in range(9):\n",
    "        axs[i].set_ylabel('Price')\n",
    "        axs[i].set_xlim(auto = True)\n",
    "        axs[i].set_ylim(auto = True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# sns.jointplot(x=\"x\", y=\"price\", data=df,kind='scatter',stat_func=sci.pearsonr,s=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# sns.jointplot(x=\"y\", y=\"price\", data=df,kind='scatter',stat_func=sci.pearsonr,s=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# sns.jointplot(x=\"z\", y=\"price\", data=df,kind='scatter',stat_func=sci.pearsonr,s=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# sns.jointplot(x=\"cut\", y=\"price\", data=df,kind='scatter',stat_func=sci.pearsonr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# sns.jointplot(x=\"carat\", y=\"price\", data=df,kind='scatter',stat_func=sci.pearsonr,s=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# sns.jointplot(x=\"depth\", y=\"price\", data=df,kind='scatter',stat_func=sci.pearsonr,s=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# sns.jointplot(x=\"table\", y=\"price\", data=df,kind='scatter',stat_func=sci.pearsonr,s=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Standardize\n",
    "    Xs_train_set_mean = X_train.mean()                          \n",
    "    Xs_train_set_std  = X_train.std()\n",
    "    Xs_train_set      = (X_train - Xs_train_set_mean) / Xs_train_set_std\n",
    "    Xs_test_set       = (X_test  - Xs_train_set_mean) / Xs_train_set_std\n",
    "    \n",
    "    fig, axs = plt.subplots(3, 3, figsize=(18, 10))\n",
    "    axs = axs.ravel()\n",
    "    axs[0].scatter(Xs_test_set.carat,   y_test, alpha = 0.2, s = 1)\n",
    "    axs[0].set_xlabel('Carat')\n",
    "    axs[1].scatter(Xs_test_set.cut,     y_test, alpha = 0.2, s = 1)\n",
    "    axs[1].set_xlabel('Cut')\n",
    "    axs[2].scatter(Xs_test_set.color,   y_test, alpha = 0.2, s = 1)\n",
    "    axs[2].set_xlabel('Color')\n",
    "    axs[3].scatter(Xs_test_set.clarity, y_test, alpha = 0.2, s = 1)\n",
    "    axs[3].set_xlabel('Clarity')\n",
    "    axs[4].scatter(Xs_test_set.depth,   y_test, alpha = 0.2, s = 1)\n",
    "    axs[4].set_xlabel('Depth')\n",
    "    axs[5].scatter(Xs_test_set.table,   y_test, alpha = 0.2, s = 1)\n",
    "    axs[5].set_xlabel('Table')\n",
    "    axs[6].scatter(Xs_test_set.x,       y_test, alpha = 0.2, s = 1)\n",
    "    axs[6].set_xlabel('x')\n",
    "    axs[7].scatter(Xs_test_set.y,       y_test, alpha = 0.2, s = 1)\n",
    "    axs[7].set_xlabel('y')\n",
    "    axs[8].scatter(Xs_test_set.z,       y_test, alpha = 0.2, s = 1)\n",
    "    axs[8].set_xlabel('z')\n",
    "    for i in range(9):\n",
    "        axs[i].set_ylabel('Price')\n",
    "        axs[i].set_xlim(auto = True)\n",
    "        axs[i].set_ylim(auto = True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "#     sns.jointplot(x=\"z\", y=\"price\", data=Xs_train_set,kind='scatter',stat_func=sci.pearsonr,s=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method is for print the time easily\n",
    "def PrintResult(regressor, label):\n",
    "    start_time = datetime.datetime.now()\n",
    "#     regressor.fit(X_train, y_train)#Estimators\n",
    "    regressor.fit(Xs_train_set, y_train)#Estimators\n",
    "#     y_pred = regressor.predict(X_test)#predict after fit\n",
    "    y_pred = regressor.predict(Xs_test_set)#predict after fit\n",
    "    \n",
    "    end_time = datetime.datetime.now()  # Track learning ending time\n",
    "    exection_time = (end_time - start_time).total_seconds()  # Track execution time\n",
    "    \n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "    RMSE = math.pow(mean_squared_error(y_test, y_pred), 0.5)#RMSE = mean_squared_error(y_test, y_pred)**0.5 #same\n",
    "    R2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"--------------------------\")\n",
    "    print(\"Regressor: \" + label)\n",
    "    print(label + ' MSE    : %0.2f ' % MSE)\n",
    "    print(label + ' RMSE   : %0.2f ' % RMSE)\n",
    "    print(label + ' R2     : %0.2f ' % R2)\n",
    "    print(label + ' MAE    : %0.2f ' % MAE)\n",
    "    print(\"Learn: execution time={t:.3f} seconds\".format(t = exection_time))\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintResult(LinearRegression(), \"Linear Regression\")\n",
    "PrintResult(KNeighborsRegressor(), \"K-Neighbors Regression\")\n",
    "# printscoresforandrew(KNeighborsRegressor(n_neighbors=12), \"K-Neighbors Regression -2\")#n_neighbors=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintResult(Ridge(), \"Ridge Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintResult(DecisionTreeRegressor(), \"Decision Tree Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintResult(RandomForestRegressor(), \"Random Forest Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintResult(GradientBoostingRegressor(), \"Gradient Boosting Regression\")\n",
    "PrintResult(SGDRegressor(), \"SGD Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintResult(SVR(), \"Support Vector Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintResult(LinearSVR(), \"LinearSVR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintResult(MLPRegressor(), \"Multi-layer Perceptron Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after tuning\n",
    "PrintResult(LinearRegression(), \"Linear Regression\")\n",
    "PrintResult(KNeighborsRegressor(n_neighbors=11,weights='distance'), \"KNN\")\n",
    "PrintResult(Ridge(), \"Ridge Regression\")  \n",
    "PrintResult(DecisionTreeRegressor(max_depth=9), \"Decision Tree\")\n",
    "PrintResult(RandomForestRegressor(max_depth=9, random_state=0, n_estimators=700), \"Random Forest\")  \n",
    "PrintResult(GradientBoostingRegressor(max_depth=5, n_estimators=1000,learning_rate=0.02, loss='ls'), \"Gradient Boosting\")\n",
    "PrintResult(SGDRegressor(), \"SGD\")\n",
    "PrintResult(SVR(C =500.0), \"SVR\")\n",
    "PrintResult(LinearSVR(C=5.0,dual=True,loss='squared_epsilon_insensitive'), \"LinearSVR\")\n",
    "PrintResult(MLPRegressor(learning_rate_init=0.2,solver='lbfgs',activation='relu'), \"MLP\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-28fbb81f",
   "language": "python",
   "display_name": "PyCharm (COMP309_A4)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}